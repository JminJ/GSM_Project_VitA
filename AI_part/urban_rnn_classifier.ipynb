{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "urban_rnn_classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YrRHkcO231X"
      },
      "source": [
        "### Load necessary libraries ###\r\n",
        "import glob\r\n",
        "import os\r\n",
        "import librosa\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uJ5uC4n2-SB"
      },
      "source": [
        "### Define helper functions ###\r\n",
        "def extract_features(parent_dir, sub_dirs, file_ext=\"*.wav\", \r\n",
        "                     bands=20, frames=41):\r\n",
        "    def _windows(data, window_size):\r\n",
        "        start = 0\r\n",
        "        while start < len(data):\r\n",
        "            yield start, start + window_size\r\n",
        "            start += (window_size // 2)    \r\n",
        "\r\n",
        "    window_size = 512 * (frames - 1)\r\n",
        "    features, labels = [], []\r\n",
        "    for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\r\n",
        "        segment_mfcc, segment_labels = [], []\r\n",
        "        sound_clip, sr = librosa.load(fn)\r\n",
        "        label = int(fn.split('/')[6].split('-')[1])\r\n",
        "        for (start,end) in _windows(sound_clip,window_size):\r\n",
        "            if(len(sound_clip[start:end]) == window_size):\r\n",
        "                signal = sound_clip[start:end]\r\n",
        "                mfcc = librosa.feature.mfcc(y=signal, sr=sr, \r\n",
        "                        n_mfcc=bands).T.flatten()[:, np.newaxis].T\r\n",
        "                segment_mfcc.append(mfcc)\r\n",
        "                segment_labels.append(label)\r\n",
        "                \r\n",
        "        segment_mfcc = np.asarray(segment_mfcc).reshape(\r\n",
        "            len(segment_mfcc),frames,bands)\r\n",
        "        \r\n",
        "        if len(segment_mfcc) > 0: # check for empty segments \r\n",
        "            features.append(segment_mfcc)\r\n",
        "            labels.append(segment_labels) \r\n",
        "            \r\n",
        "    return features, labels"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOtTrVZE3A5S"
      },
      "source": [
        "### this code is saving dataset!!! Please be careful if you have already preprocessed dataset. \r\n",
        "parent_dir = '/content/drive/MyDrive/audio/'\r\n",
        "save_dir = \"/content/drive/MyDrive/urban_audio_rnn/\"\r\n",
        "folds = sub_dirs = np.array(['fold1','fold2','fold3','fold4',\r\n",
        "                  'fold5','fold6','fold7','fold8',\r\n",
        "                  'fold9','fold10'])\r\n",
        "for sub_dir in sub_dirs:\r\n",
        "    features, labels = extract_features(parent_dir,sub_dir)\r\n",
        "    np.savez(\"{0}{1}\".format(save_dir, sub_dir), features=features, \r\n",
        "             labels=labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4VNjbW33Db8"
      },
      "source": [
        "### Define GRU based recurrent network architecture ###\r\n",
        "def get_network():\r\n",
        "    input_shape = (41, 20)\r\n",
        "    num_classes = 10\r\n",
        "    keras.backend.clear_session()\r\n",
        "    \r\n",
        "    model = keras.models.Sequential()\r\n",
        "    model.add(keras.layers.GRU(128, input_shape=input_shape))\r\n",
        "    model.add(keras.layers.Dense(128, activation=\"relu\"))\r\n",
        "    #\r\n",
        "    model.add(keras.layers.Dropout(rate = 0.2))\r\n",
        "    #\r\n",
        "    model.add(keras.layers.Dense(num_classes, activation = \"softmax\"))\r\n",
        "    model.compile(optimizer=keras.optimizers.Adam(1e-4), \r\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(), \r\n",
        "        metrics=[\"accuracy\"])\r\n",
        "    \r\n",
        "    return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jge28NM3F0b"
      },
      "source": [
        "### Train and evaluate via 10-Folds cross-validation ###\r\n",
        "accuracies = []\r\n",
        "folds = np.array(['fold1','fold2','fold3','fold4',\r\n",
        "                  'fold5','fold6','fold7','fold8',\r\n",
        "                  'fold9','fold10'])\r\n",
        "load_dir = \"/content/drive/MyDrive/urban_audio_rnn/\"\r\n",
        "kf = KFold(n_splits=10)\r\n",
        "i = -1\r\n",
        "for train_index, test_index in kf.split(folds):\r\n",
        "    i+=1\r\n",
        "    x_train, y_train = [], []\r\n",
        "    for ind in train_index:\r\n",
        "        # read features or segments of an audio file\r\n",
        "        train_data = np.load(\"{0}/{1}.npz\".format(load_dir,folds[ind]), \r\n",
        "                       allow_pickle=True)\r\n",
        "        # for training stack all the segments so that they are treated as an example/instance\r\n",
        "        features = np.concatenate(train_data[\"features\"], axis=0) \r\n",
        "        labels = np.concatenate(train_data[\"labels\"], axis=0)\r\n",
        "        x_train.append(features)\r\n",
        "        y_train.append(labels)\r\n",
        "    # stack x,y pairs of all training folds \r\n",
        "    x_train = np.concatenate(x_train, axis = 0).astype(np.float32)\r\n",
        "    y_train = np.concatenate(y_train, axis = 0).astype(np.float32)\r\n",
        "    \r\n",
        "    # for testing we will make predictions on each segment and average them to \r\n",
        "    # produce signle label for an entire sound clip.\r\n",
        "    test_data = np.load(\"{0}/{1}.npz\".format(load_dir,\r\n",
        "                   folds[test_index][0]), allow_pickle=True)\r\n",
        "    x_test = test_data[\"features\"]\r\n",
        "    y_test = test_data[\"labels\"]\r\n",
        "\r\n",
        "    model = get_network()\r\n",
        "    model.fit(x_train, y_train, epochs = 4, batch_size = 72, verbose = 0)\r\n",
        "    \r\n",
        "    # evaluate on test set/fold\r\n",
        "    y_true, y_pred = [], []\r\n",
        "    for x, y in zip(x_test, y_test):\r\n",
        "        # average predictions over segments of a sound clip\r\n",
        "        avg_p = np.argmax(np.mean(model.predict(x), axis = 0))\r\n",
        "        y_pred.append(avg_p) \r\n",
        "        # pick single label via np.unique for a sound clip\r\n",
        "        y_true.append(np.unique(y)[0]) \r\n",
        "    accuracies.append(accuracy_score(y_true, y_pred))   \r\n",
        "    print('accuracies{} : {}'.format(i, accuracies[-1]))\r\n",
        "print(\"Average 10 Folds Accuracy: {0}\".format(np.mean(accuracies)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}